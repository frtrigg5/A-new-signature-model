{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCDX0KTI3fkLl+3502V00b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frtrigg5/A-new-signature-model/blob/Code/Tesi_Github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PACKAGES REQUESTED**"
      ],
      "metadata": {
        "id": "S1Zh9ZmRdKiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The package signatory computes the signature. \n",
        "\n",
        "It needs an elder version of torch."
      ],
      "metadata": {
        "id": "prFOaD6QcoVB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xh1qrjFGcRN9"
      },
      "outputs": [],
      "source": [
        "!pip uninstall torch -y\n",
        "!pip install torch==1.7.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running the first cell you will need to restart the runtime."
      ],
      "metadata": {
        "id": "oRmhcwGbc1up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "abkdlzGBcdi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install signatory==1.2.6.1.7.1\n",
        "!pip install fbm"
      ],
      "metadata": {
        "id": "e72CGxtaceal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import signatory\n",
        "import fbm\n",
        "from scipy import optimize\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "aHNQxaakcgvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL DEFINITION**"
      ],
      "metadata": {
        "id": "2kRBuuOVdStN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "New layers construction:"
      ],
      "metadata": {
        "id": "_UrxmpmkdmdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#phi function\n",
        "def phi(x,C,a): #x stands for the squared norm of the truncated signature\n",
        "  if x>C:\n",
        "    return C+(C**(1+a))*(C**(-a)-x**(-a))/a \n",
        "  else:\n",
        "    return x\n",
        "\n",
        "def dilatation(x,C,a,L,d): #x is the truncated signature, C and a are phi parameters, L is the cut off level, d is the path dimension\n",
        "  xNumpy=x.detach().numpy()\n",
        "  coefficients=np.zeros((xNumpy.shape[0],(L+1))) \n",
        "  normalizz=np.zeros((xNumpy.shape[0],1)) \n",
        "  for i in range(0,xNumpy.shape[0]):\n",
        "      normQuad=1+np.sum(xNumpy[i]**2)\n",
        "      coefficients[i,0]=1-phi(normQuad,C,a) \n",
        "      for j in range(1,(L+1)):\n",
        "         coefficients[i,j]=np.sum(xNumpy[i,int(((d**j-1)/(d-1)-1)):int(((d**(j+1)-1)/(d-1)-1))]**2)\n",
        "      def polin(input):\n",
        "        xMonomials=np.zeros((L+1))+1\n",
        "        for k in range(1,(L+1)):\n",
        "            xMonomials[k]=input**(2*k)\n",
        "        return np.dot(xMonomials,coefficients[i])  \n",
        "      normalizz[i]=optimize.brentq(polin,0,2)\n",
        "      if normalizz[i]>1:\n",
        "        normalizz[i]=1\n",
        "  return torch.from_numpy(normalizz) \n",
        "\n",
        "#Transforming a vector in a lower diagonal matrix\n",
        "class Triangular(nn.Module):\n",
        "  def __init__(self,batch,dim,L2): #batch is the batch number, dim is the dimension of the original timeseries, L2 is the value of new timesteps\n",
        "    super(Triangular,self).__init__()\n",
        "    self.dim=dim\n",
        "    self.batch=batch\n",
        "    self.L2=L2\n",
        "    self.tril_indices=torch.tril_indices(row=(self.dim*self.L2),col=(self.dim*self.L2),offset=0)\n",
        "    \n",
        "  def forward(self,x): \n",
        "      m=torch.zeros((self.batch,(self.dim*self.L2),(self.dim*self.L2)),device=device)\n",
        "      m[:,self.tril_indices[0],self.tril_indices[1]]=x \n",
        "      return m\n",
        "#Introducing the new values and the time component\n",
        "class PreparationWithTimeAugmentation(nn.Module): \n",
        "  def __init__(self,order,timesteps_cut,dim,extended_order): #timesteps_cut=L1+L2\n",
        "    super(PreparationWithTimeAugmentation,self).__init__()\n",
        "    self.order=order  \n",
        "    self.extended_order=extended_order\n",
        "    self.cut=timesteps_cut \n",
        "    self.d=dim\n",
        "\n",
        "  def forward(self,x,y): #x is the original input, y the new values obtained by the sampling layer\n",
        "      timesteps=x[:,:self.cut] # \n",
        "      values=x[:,self.cut:]\n",
        "      values=torch.cat((values,y),1) \n",
        "      values=values[:,self.extended_order.type(torch.LongTensor)] \n",
        "      values=values.reshape([values.shape[0],self.cut,self.d])\n",
        "      timesteps=timesteps[:,self.order]\n",
        "      Path=torch.cat((values,timesteps.unsqueeze(2)),2)\n",
        "      return Path"
      ],
      "metadata": {
        "id": "Az_3GGw1dYYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Model:"
      ],
      "metadata": {
        "id": "ivyxokYNdskG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyFinalModel2(nn.Module):\n",
        "  def __init__(self,L1,L2,dim,div,level,number_classes,C,a): #L1 is the length of the starting time series, L2 number of new time stamps,\n",
        "                                                             #dim is the dimension of the time series, level=L the truncation level,\n",
        "                                                             #C and a are phi parameter\n",
        "     super(MyFinalModel2,self).__init__()\n",
        "     self.C,self.a,self.L1,self.L2,self.dim,self.div=C,a,L1,L2,dim,div\n",
        "     Known_times=torch.linspace(start=0,end=1,steps=self.L1) \n",
        "     New_times=torch.zeros(self.div*(self.L1-1))\n",
        "     for i in range(0,(self.L1-1)):\n",
        "         New_times[(self.div*i):(self.div*(i+1))]=torch.linspace(start=Known_times[i],end=Known_times[i+1],steps=(self.div+2))[1:(1+self.div)]\n",
        "     timesteps=torch.cat((Known_times,New_times),0)\n",
        "     self.order=torch.sort(timesteps)[1] #indicates how the new and known time stamps should be ordered\n",
        "     self.extended_order=torch.zeros(self.dim*self.order.size(0)) \n",
        "     for i in range(0,self.order.size(0)):\n",
        "        self.extended_order[(i*self.dim):((i+1)*self.dim)]=torch.arange(self.order[i]*self.dim,(self.order[i]+1)*self.dim)\n",
        "     #extended_order is useful for introducing the new values \n",
        "     self.MatrixDim=int((self.dim*self.L2)*(self.dim*self.L2+1)/2)\n",
        "     self.level=level\n",
        "     self.number_classes=number_classes\n",
        "     self.outputSigDim=int((((self.dim+1)**(self.level+1))/(self.dim))-1)\n",
        "\n",
        "     self.exponents=torch.ones(int(((self.dim+1)**(self.level+1)-1)/self.dim-1))\n",
        "     for j in range(2,(self.level+1)):\n",
        "         self.exponents[int((((self.dim+1)**j-1)/(self.dim)-1)):int((((self.dim+1)**(j+1)-1)/(self.dim)-1))]=torch.ones((int(self.dim+1)**j))*j\n",
        "     #exponents is useful for normalizing the signature\n",
        "     self.meanLayer= nn.Linear((self.L1*(self.dim+1)+self.L2),(self.L2*self.dim))\n",
        "     self.sqrtCovLayer=nn.Linear((self.L1*(self.dim+1)+self.L2),self.MatrixDim) \n",
        "     self.finaLayer1=nn.Linear(self.outputSigDim,self.number_classes) \n",
        "     self.N=torch.distributions.Normal(0,1) #sampling layer\n",
        "     self.Sig=signatory.Signature(self.level) #signature computation\n",
        "     self.LogSoftmax=nn.LogSoftmax(1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    self.mean=self.meanLayer(x) \n",
        "    sqrtCov=self.sqrtCovLayer(x)\n",
        "    self.sqrtCovMatrix=Triangular(x.shape[0],self.dim,self.L2)(sqrtCov)\n",
        "    #K=2\n",
        "    self.epsilon1=self.N.sample(self.mean.shape).to(device)    \n",
        "    self.New_values1=(torch.bmm(self.sqrtCovMatrix,self.epsilon1.unsqueeze(2))).squeeze(2)+self.mean \n",
        "    self.Path1=PreparationWithTimeAugmentation(self.order,self.L1+self.L2,self.dim,self.extended_order)(x,self.New_values1)\n",
        "    self.epsilon2=self.N.sample(self.mean.shape) .to(device)     \n",
        "    self.New_values2=(torch.bmm(self.sqrtCovMatrix,self.epsilon2.unsqueeze(2))).squeeze(2)+self.mean \n",
        "    self.Path2=PreparationWithTimeAugmentation(self.order,self.L1+self.L2,self.dim,self.extended_order)(x,self.New_values2)   \n",
        "    #computation of signature and normalized signature                                                                            \n",
        "    self.Sig1= self.Sig(self.Path1)\n",
        "    self.norm1=dilatation(self.Sig1,self.C,self.a,self.level,self.dim+1)\n",
        "    self.Sig1=(self.Sig1*(self.norm1**self.exponents)).type(torch.float32)\n",
        "    self.Sig2=self.Sig(self.Path2)\n",
        "    self.norm2=dilatation(self.Sig2,self.C,self.a,self.level,self.dim+1)\n",
        "    self.Sig2=(self.Sig2*(self.norm2**self.exponents)).type(torch.float32)   \n",
        "    #computation of normalized expected signature and supervised part\n",
        "    self.MeanSig=torch.stack((self.Sig1,self.Sig2),2)\n",
        "    self.MeanSig=torch.mean(self.MeanSig,2)\n",
        "    output=self.finaLayer1(self.MeanSig)\n",
        "    output=self.LogSoftmax(output)\n",
        "    return output    "
      ],
      "metadata": {
        "id": "X0iHy0FHdvXP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}