{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frtrigg5/A-new-signature-model/blob/main/ModelConstruction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PACKAGES REQUESTED**"
      ],
      "metadata": {
        "id": "S1Zh9ZmRdKiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The package signatory computes the signature (check https://pypi.org/project/signatory/ to see its documentation).\n",
        "\n",
        "It needs an elder version of torch."
      ],
      "metadata": {
        "id": "prFOaD6QcoVB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xh1qrjFGcRN9"
      },
      "outputs": [],
      "source": [
        "!pip uninstall torch -y\n",
        "!pip install torch==1.7.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running the first cell you will need to restart the runtime."
      ],
      "metadata": {
        "id": "oRmhcwGbc1up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "abkdlzGBcdi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install signatory==1.2.6.1.7.1\n",
        "!pip install fbm"
      ],
      "metadata": {
        "id": "e72CGxtaceal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import signatory\n",
        "import fbm\n",
        "from scipy import optimize\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "aHNQxaakcgvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL DEFINITION**"
      ],
      "metadata": {
        "id": "2kRBuuOVdStN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "New layers construction:"
      ],
      "metadata": {
        "id": "_UrxmpmkdmdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''phi function: the ones needed for computing the tensor normalization'''\n",
        "\n",
        "def phi(x,C,a):\n",
        "\n",
        "'''  x: signature norm squared\n",
        "  C: phi function parameter, it controls how strict the normalization is\n",
        "  a: phi function parameter, tipically fixed to 1 in order to avoid too much hyperparameter'''\n",
        "\n",
        "  if x>C:\n",
        "    return C+(C**(1+a))*(C**(-a)-x**(-a))/a\n",
        "  else:\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "'''dilatation function: it determines the normalization constant lambda (see graphical representation of the model, layer 6)'''\n",
        "\n",
        "def dilatation(x,C,a,M,d):\n",
        "\n",
        "  '''x: an array with dimension batch x signature\n",
        "  C,a : phi function parameters\n",
        "  M : truncation level (called L in the paper)\n",
        "  d : dimension of the time series we are computing the signature of (!! if time augmentation is deployed, then the dimension is increased by 1)'''\n",
        "\n",
        "  xNumpy=x.detach().numpy()\n",
        "\n",
        "  coefficients=numpy.zeros((xNumpy.shape[0],(M+1)))\n",
        "  normalizz=numpy.zeros((xNumpy.shape[0],1))\n",
        "  for i in range(0,xNumpy.shape[0]):\n",
        "      normQuad=1+numpy.sum(xNumpy[i]**2) #signature norm squared\n",
        "      coefficients[i,0]=1-phi(normQuad,C,a)\n",
        "      for j in range(1,(M+1)):\n",
        "         coefficients[i,j]=numpy.sum(xNumpy[i,int(((d**j-1)/(d-1)-1)):int(((d**(j+1)-1)/(d-1)-1))]**2)\n",
        "      def polin(input):\n",
        "        xMonomials=numpy.zeros((M+1))+1\n",
        "        for k in range(1,(M+1)):\n",
        "            xMonomials[k]=input**(2*k)\n",
        "        return numpy.dot(xMonomials,coefficients[i])\n",
        "      normalizz[i]=optimize.brentq(polin,0,2)\n",
        "      if normalizz[i]>1:\n",
        "        normalizz[i]=1\n",
        "  return torch.from_numpy(normalizz)\n",
        "\n",
        "\n",
        "'''grad computation of dilatation function (corollary B.14 in the paper)\n",
        "'''\n",
        "class Normalization(torch.autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx,input,C,M,d,exponents): #a=1, input should have dimension batch x length_sign, M is the truncation level, d the dimension of the timeseries, C normalization constant, exponents is useful to define correctly the dilatation\n",
        "      '''input: an array batch x signature, it is x in the previous function\n",
        "      C, M ,d: as in the previous function\n",
        "      exponents: a vector as long as the signature, it has d times 1, d^2 times 2,..., d^M times the value M'''\n",
        "\n",
        "      norm=dilatation(input,C,1,M,d)\n",
        "      ctx.save_for_backward(input,exponents)\n",
        "      ctx.C=C\n",
        "      ctx.M=M\n",
        "      ctx.d=d\n",
        "      ctx.norm=norm #batchx1\n",
        "      return norm.to(torch.float32)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "      '''grad_output: grad of upper layers'''\n",
        "\n",
        "      input,exponents=ctx.saved_tensors\n",
        "      normToSquarePower=(ctx.norm**(2*exponents)).to(torch.float64) #batch x length_sign\n",
        "      normToSquarePowerMinus1=(ctx.norm**(2*exponents-1)).to(torch.float64) #batch x length_sign\n",
        "      denominator=torch.sum((input**2)*(normToSquarePowerMinus1),1,keepdim=True) #batch x 1\n",
        "      inputnorm=(1+torch.sum(input**2,1,keepdim=True))**(1/2) # batch x 1 ,norm of the pre-normalized signature\n",
        "\n",
        "      #computing phi derivative based on the 2 branches of the phi function\n",
        "      phiDerivative=torch.zeros(input.shape[0],1,dtype=torch.float64) #batch x 1\n",
        "      #second branch\n",
        "      index1=torch.where(inputnorm[:,0]>(ctx.C)**(1/2))[0]\n",
        "      if len(index1)>0:\n",
        "        phiDerivative[index1,:]=2*(ctx.C)**2/(inputnorm[index1,:]**3)\n",
        "      #first branch\n",
        "      index2=torch.where(inputnorm[:,0]<=(ctx.C)**(1/2))[0]\n",
        "      if len(index2)>0:\n",
        "        phiDerivative[index2,:]=2*inputnorm[index2,:]\n",
        "      #Numerator\n",
        "      Numerator=normToSquarePower-(phiDerivative/(2*inputnorm))*torch.ones(input.shape[0],int((ctx.d**(ctx.M+1)-1)/(ctx.d-1)-1)) #batch x length_sign\n",
        "      Numerator=input*Numerator\n",
        "      gradient=Numerator/denominator #batch x length_sign\n",
        "      return grad_output*gradient, None, None, None, None\n",
        "\n",
        "\n",
        "'Triangular: transformed a vector into a lower triangular matrix'\n",
        "class Triangular(torch.nn.Module):\n",
        "  def __init__(self,dim,L2,x_indices,y_indices):\n",
        "    '''dim: dimension of the starting time series\n",
        "    L2: number of new time instants\n",
        "    x_indices, y_indices: explained in the model construction (below)'''\n",
        "\n",
        "    super(Triangular,self).__init__()\n",
        "    self.dim=dim\n",
        "    self.L2=L2\n",
        "    self.x_indices=x_indices\n",
        "    self.y_indices=y_indices\n",
        "\n",
        "\n",
        "  def forward(self,x): #x is of size batch x int((int(L2*(L2+1)/2)-int((L2-alp)*(L2-alp+1)/2))*(int(dim*(dim+1)/2)))\n",
        "      A=torch.zeros((x.shape[0],self.L2*self.dim,self.L2*self.dim))\n",
        "      A[:,torch.Tensor.long(self.x_indices),torch.Tensor.long(self.y_indices)]=x\n",
        "      return A\n",
        "\n",
        "\n",
        "'''Preparation with time augmentation: combines original time series and values sampled, then applies time augmentation'''\n",
        "\n",
        "class PreparationWithTimeAugmentation(torch.nn.Module):\n",
        "  def __init__(self,order,timesteps_cut,dim,extended_order):\n",
        "    '''dim: as in the previous function\n",
        "    timesteps_cut: number of time steps, sum of known an new time steps\n",
        "    order, extended_order: explained in the model'''\n",
        "\n",
        "    super(PreparationWithTimeAugmentation,self).__init__()\n",
        "    self.order=order\n",
        "    self.extended_order=extended_order\n",
        "    self.cut=timesteps_cut\n",
        "    self.d=dim\n",
        "\n",
        "  def forward(self,x,y):\n",
        "'''    x: starting time series\n",
        "    y: new values sampled'''\n",
        "\n",
        "      timesteps=x[:,:self.cut] # time instants: before known and then new ones\n",
        "      values=x[:,self.cut:] #starting time series\n",
        "      values=torch.cat((values,y),1) #concatenate values with the new values\n",
        "      #reorder values\n",
        "      values=values[:,self.extended_order.type(torch.LongTensor)]\n",
        "      values=values.reshape([values.shape[0],self.cut,self.d])\n",
        "      #adding time component\n",
        "      timesteps=timesteps[:,self.order]\n",
        "      Path=torch.cat((values,timesteps.unsqueeze(2)),2)\n",
        "      return Path\n",
        "\n"
      ],
      "metadata": {
        "id": "Az_3GGw1dYYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Model\n",
        "IMPORTANT: IT IS BUILT IN A SPECIFIC WAY, SO IT NEEDS THAT THE INPUT IS STRUCTURED AS FOLLOWS:\n",
        "- FIRSTLY, KNOWN TIMES INSTANTS\n",
        "- SECONDLY, NEW TIMES INSTANTS\n",
        "- LASTLY THE TIME SERIES VALUES WHERE IF THE TIME SERIES IS D- DIMENSIONAL, THEN THERE ARE THE D VALUES OF THE FIRST ELEMENT OF THE TIME SERIES, FOLLOWED BY THE D VALUES OF THE SECOND ELEMENT OF THE TIME SERIES AND SO ON"
      ],
      "metadata": {
        "id": "ivyxokYNdskG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(torch.nn.Module):\n",
        "\n",
        "  def __init__(self,L1,L2,dim,order,extended_order,alp,level,number_classes,C,a,K):\n",
        "'''\n",
        "     L1 : number of known time instants, i.e. length of the time series\n",
        "     L2 : number of new time instants\n",
        "     order : in Preparationwithtimeaugmentation we concatenate the starting values and the sampled one, order reorganize them (FOR EXAMPLE L1=100, L2=99, THEN ORDER=[0,100,1,101,2,102,..] IF THE NEW TIME INSTANTS ARE THE MIDDLE POINTS)\n",
        "     extended_order: as order but takes into account the dimension of the time series (FOR EXAMPLE D=2, L1=100,L2=99 SO STARTING TIME SERIES HAS 200 VALUES AND NEW VALUES ARE 198, SO EXTENDED ORDER=[0,1,200,201,2,3,202,203,...])\n",
        "     ALP : how many subdiagonals of the lower triangular matrix are non zero, alp=L2 means no zero in the lower part\n",
        "     level : signature truncation level (called M above)\n",
        "     number_classes : number of labels in the classification problem\n",
        "     C,a : phi function parameters\n",
        "     K : numbers of augmented paths generated\n",
        "     dim : dimension of the starting time series'''\n",
        "\n",
        "     super(MyModel,self).__init__()\n",
        "     self.K=K\n",
        "     self.C=C\n",
        "     self.a=a\n",
        "     self.alp=alp\n",
        "     self.L1=L1\n",
        "     self.L2=L2\n",
        "     self.dim=dim\n",
        "     self.order=order\n",
        "     self.extended_order=extended_order\n",
        "     #compute how much elements in the lower triangular matrix\n",
        "     self.MatrixEl=int((int(self.L2*(self.L2+1)/2)-int((self.L2-self.alp)*(self.L2-self.alp+1)/2))*(int(self.dim*(self.dim+1)/2)))\n",
        "     self.level=level\n",
        "     self.number_classes=number_classes\n",
        "     #number of components of the signature (remember we have time augmentation)\n",
        "     self.outputSigDim=int(((self.dim+1)**(self.level+1)-1)/(self.dim)-1)\n",
        "     #bulding the exponents useful for normalization procedure\n",
        "     self.exponents=torch.ones(int(((self.dim+1)**(self.level+1)-1)/self.dim-1)).to(torch.float64)\n",
        "     for j in range(2,(self.level+1)):\n",
        "         self.exponents[int((((self.dim+1)**j-1)/(self.dim)-1)):int((((self.dim+1)**(j+1)-1)/(self.dim)-1))]=torch.ones((int(self.dim+1)**j))*j\n",
        "\n",
        "     #needed to reshape first layer output into a matrix (in triangular function)\n",
        "     self.tril_indices=torch.tril_indices(row=(self.dim),col=(self.dim),offset=0)\n",
        "     self.x_indices=torch.zeros(int(self.L2*(self.L2+1)/2)-int((self.L2-self.alp)*(self.L2-self.alp+1)/2),dtype=torch.int32)\n",
        "     for i in range(self.alp):\n",
        "        self.x_indices[i*self.L2-int(i*(i-1)/2):(i+1)*self.L2-int((i+1)*i/2)]=torch.arange(i,self.L2,1)\n",
        "\n",
        "     self.y_indices=torch.zeros(int(self.L2*(self.L2+1)/2)-int((self.L2-self.alp)*(self.L2-self.alp+1)/2),dtype=torch.int32)\n",
        "     for i in range(self.alp):\n",
        "        self.y_indices[i*self.L2-int(i*(i-1)/2):(i+1)*self.L2-int((i+1)*i/2)]=torch.arange(0,self.L2-i,1)\n",
        "\n",
        "     self.x_indicesFull=torch.zeros(int((int(self.L2*(self.L2+1)/2)-int((self.L2-self.alp)*(self.L2-self.alp+1)/2))*(int(self.dim*(self.dim+1)/2))),dtype=torch.int32)\n",
        "     self.y_indicesFull=torch.zeros(int((int(self.L2*(self.L2+1)/2)-int((self.L2-self.alp)*(self.L2-self.alp+1)/2))*(int(self.dim*(self.dim+1)/2))),dtype=torch.int32)\n",
        "     for j in range(self.x_indices.shape[0]):\n",
        "       self.x_indicesFull[(j*int(self.dim*(self.dim+1)/2)):((j+1)*int(self.dim*(self.dim+1)/2))]=(self.x_indices[j]*self.dim)+self.tril_indices[0]\n",
        "       self.y_indicesFull[(j*int(self.dim*(self.dim+1)/2)):((j+1)*int(self.dim*(self.dim+1)/2))]=(self.y_indices[j]*self.dim)+self.tril_indices[1]\n",
        "\n",
        "\n",
        "\n",
        "     self.meanLayer= torch.nn.Linear((self.L1*(self.dim+1)+self.L2),(self.L2*self.dim))#(L1+L2+L1*d,L2*d)\n",
        "     self.sqrtCovLayer=torch.nn.Linear((self.L1*(self.dim+1)+self.L2),self.MatrixEl)\n",
        "     self.finaLayer1=torch.nn.Linear(self.outputSigDim,self.number_classes) #2 classi  #usando piÃƒÆ’Ã‚Â¹ layer poi conviene mettere delle funzioni di attivazione, altrimenti ÃƒÆ’Ã‚Â¨ inutile andare deep\n",
        "     self.Normalization=()\n",
        "     self.N=torch.distributions.Normal(0,1)\n",
        "     self.Sig=signatory.Signature(self.level)\n",
        "     self.LogSoftmax=torch.nn.LogSoftmax(1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    self.mean=self.meanLayer(x)\n",
        "    sqrtCov=self.sqrtCovLayer(x)\n",
        "    self.sqrtCovMatrix=Triangular(self.dim,self.L2,self.x_indicesFull,self.y_indicesFull)(sqrtCov)\n",
        "    self.epsilon=self.N.sample(torch.Size([x.shape[0],self.L2*self.dim,self.K]))\n",
        "    self.NewValues=torch.bmm(self.sqrtCovMatrix,self.epsilon)+self.mean.unsqueeze(2)\n",
        "\n",
        "    self.Signatures=torch.zeros(x.shape[0],self.outputSigDim,self.K)\n",
        "    for i in range(self.K):\n",
        "      Path=PreparationWithTimeAugmentation(self.order,self.L1+self.L2,self.dim,self.extended_order)(x,self.NewValues[:,:,i])\n",
        "      Sig=self.Sig(Path)\n",
        "      norm=Normalization.apply(Sig.to(torch.float64),self.C,self.level,self.dim+1,self.exponents)\n",
        "      self.Signatures[:,:,i]=(Sig*(norm**self.exponents)).type(torch.float32)\n",
        "\n",
        "\n",
        "    self.MeanSig=torch.mean(self.Signatures,2)\n",
        "    output=self.finaLayer1(self.MeanSig)\n",
        "    output=self.LogSoftmax(output)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "X0iHy0FHdvXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of order and extended order construction"
      ],
      "metadata": {
        "id": "SppPZhdxROLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "begin,end,number,division,dim=0,1,100,1,1\n",
        "'''division=1 means we are taking the middle points as new time instants->L2=L1-1\n",
        "number=L1\n",
        "begin=first time steps\n",
        "end=last known time steps'''\n",
        "\n",
        "#generating the time steps\n",
        "Known_times=torch.linspace(begin,end,number)\n",
        "New_times=torch.zeros(division*(number-1))\n",
        "for i in range(0,(number-1)):\n",
        "  New_times[(division*i):(division*(i+1))]=torch.linspace(Known_times[i],Known_times[i+1],(division+2))[1:(1+division)]\n",
        "#Length of known values and new values\n",
        "L1=Known_times.shape[0]\n",
        "L2=New_times.shape[0]\n",
        "\n",
        "timesteps=torch.cat((Known_times,New_times),axis=0)\n",
        "timesteps_sorted,order=torch.sort(timesteps)\n",
        "\n",
        "extended_order=torch.zeros(dim*order.size(0))\n",
        "for i in range(0,order.size(0)):\n",
        "  extended_order[(i*dim):((i+1)*dim)]=torch.arange(order[i]*dim,(order[i]+1)*dim)"
      ],
      "metadata": {
        "id": "LqKs1fqyRSGR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}